{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szymonkulpinski/colab_notebooks/blob/main/teams_clustering_siglip2_image_visualization_backu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9isDqFGjifx_"
      },
      "source": [
        "### Check if GPU is in use\n",
        "If this command fails: click in the upper-right corner of this window ![image.png](data:image/png;base64,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)\n",
        " and select `Change runtime type` and then select `T4 GPU`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V73085Fyzi-7",
        "outputId": "9daf72c0-0af7-4a0c-ed54-e5ad4fb7e4f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 16 07:09:34 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGyxy15w3O2S"
      },
      "source": [
        "### Install all dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoW-AJ_hw9k9",
        "outputId": "17388757-c5f0-457f-cc90-428fbcbfd3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading uv 0.7.4 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n"
          ]
        }
      ],
      "source": [
        "!curl -LsSf https://astral.sh/uv/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0vunXPwy3OUI"
      },
      "outputs": [],
      "source": [
        "!pip install -q roboflow supervision umap-learn tqdm adjustText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_tpn6bxzbh9",
        "outputId": "b8d7c15d-6929-4315-9dc1-000ffb1a5526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-l6a38xfb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-l6a38xfb\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XiuBC6GklNl"
      },
      "source": [
        "### Make all the relevant imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOqXXNRskomz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import umap\n",
        "import torch\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import supervision as sv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from roboflow import Roboflow\n",
        "from adjustText import adjust_text\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import KMeans\n",
        "from more_itertools import chunked\n",
        "from typing import Tuple\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import AutoFeatureExtractor, ResNetModel, AutoProcessor, SiglipVisionModel, CLIPProcessor, CLIPVisionModel, Siglip2VisionModel, AutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3snN3dJTKvYS"
      },
      "source": [
        "### Define constants and settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRm5l_GuKz2x"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  HOME = \"/content\"\n",
        "else:\n",
        "  HOME = os.getcwd()\n",
        "\n",
        "# In the used dataset all of the images have the resolution of 1920x1080px\n",
        "IMAGE_WIDTH = 1920\n",
        "IMAGE_HEIGHT = 1080\n",
        "\n",
        "# Settings\n",
        "NUM_ITERATIONS = 5 # 5 # set to 1 if you only want to evaluate once, for evalutation used 32\n",
        "BATCH_SIZE_ARRAY = [32]\n",
        "# FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering\" # where in google colab the experiments results should be saved\n",
        "# FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering_visualization_embeddings\" # where in google colab the experiments results should be saved\n",
        "# FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering_preprocess_fix\" # where in google colab the experiments results should be saved\n",
        "# FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering_preprocess_fix_fast\" # where in google colab the experiments results should be saved\n",
        "# FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering_preprocess_fix_fast_PCA\" # where in google colab the experiments results should be saved\n",
        "# FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering_preprocess_fix_fast_PCA_0KMeans\" # where in google colab the experiments results should be saved\n",
        "FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering_preprocess_fix_fast_UMAP_0KMeans\" # where in google colab the experiments results should be saved\n",
        "# FOLDER_DIR = \"/content/drive/MyDrive/0_teams-clustering_preprocess_fix_fast_tsne\"\n",
        "RUN_EXPERIMENTS = True # if set to true experiments will be run, if to false it will only read saved results\n",
        "VISUALIZE_CROPS = False\n",
        "\n",
        "VERSIONS_TO_TEST = [\n",
        "  \"google/siglip2-base-patch32-256\",\n",
        "  \"google/siglip2-base-patch16-224\",\n",
        "  \"google/siglip2-base-patch16-256\",\n",
        "  \"google/siglip2-base-patch16-384\",\n",
        "  \"google/siglip2-base-patch16-512\",\n",
        "  \"google/siglip2-base-patch16-naflex\",\n",
        "  \"google/siglip2-large-patch16-256\",\n",
        "  \"google/siglip2-large-patch16-384\",\n",
        "  \"google/siglip2-large-patch16-512\",\n",
        "  \"google/siglip2-so400m-patch14-224\",\n",
        "  \"google/siglip2-so400m-patch14-384\",\n",
        "  \"google/siglip2-so400m-patch16-256\",\n",
        "  \"google/siglip2-so400m-patch16-384\",\n",
        "  \"google/siglip2-so400m-patch16-512\",\n",
        "  \"google/siglip2-so400m-patch16-naflex\",\n",
        "  \"google/siglip2-giant-opt-patch16-256\",\n",
        "  \"google/siglip2-giant-opt-patch16-384\", #17 modele\n",
        "  \"google/siglip-base-patch16-512\",\n",
        "  \"google/siglip-base-patch16-384\",\n",
        "  \"google/siglip-base-patch16-256\",\n",
        "  \"google/siglip-base-patch16-224\",\n",
        "  \"google/siglip-large-patch16-256\",\n",
        "  \"google/siglip-large-patch16-384\",\n",
        "  \"google/siglip-so400m-patch14-384\",\n",
        "  \"google/siglip-so400m-patch14-224\",\n",
        "  \"google/siglip-so400m-patch16-256-i18n\", # tested repeatability\n",
        "  \"microsoft/resnet-18\",\n",
        "  \"microsoft/resnet-26\",\n",
        "  \"microsoft/resnet-34\",\n",
        "  \"microsoft/resnet-50\",\n",
        "  \"microsoft/resnet-101\",\n",
        "  \"microsoft/resnet-152\",\n",
        "  'openai/clip-vit-base-patch16',\n",
        "  'openai/clip-vit-base-patch32',\n",
        "  'openai/clip-vit-large-patch14',\n",
        "  'openai/clip-vit-large-patch14-336',\n",
        "]\n",
        "\n",
        "# Ablation study settings\n",
        "DO_ABLATION_STUDY = False\n",
        "# BATCH_SIZE_ARRAY = [1,2,8,32] # values used in the ablation study\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-bd85dyPKn6"
      },
      "source": [
        "### Mount your google drive to google colab be able to save the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSQEGJcsPK91"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "Path(FOLDER_DIR).mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqVm3KaS3Ywa"
      },
      "source": [
        "### Get the dataset and adjust the folder structure\n",
        "If you haven't added your `ROBOFLOW_API_KEY` to your secrets in Google Colab, this code snippet will fail. Follow the instructions in this [Roboflow Notebook](https://colab.research.google.com/github/roboflow/sports/blob/main/examples/soccer/notebooks/train_player_detector.ipynb#scrollTo=BSd93ZJzZZKt) to add it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkuJy44RYJ54"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "rf = Roboflow(api_key=userdata.get('ROBOFLOW_API_KEY'))\n",
        "project = rf.workspace(\"szymon-kulpinski\").project(\"football-players-clustering\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"yolov8\") # use the format as the easier to work with then e.g. COCO\n",
        "print(dataset.location)\n",
        "\n",
        "!mv {dataset.location}/train/images/* {dataset.location}/train/\n",
        "!mv {dataset.location}/train/labels/* {dataset.location}/train/\n",
        "!rm -rdf {dataset.location}/train/images\n",
        "!rm -rdf {dataset.location}/train/labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo2FZqoZ-VHk"
      },
      "source": [
        "### Load the dataset as Supervision Detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKhNgrkbkN-E"
      },
      "outputs": [],
      "source": [
        "def convert_yolov8bbox_2_xyxy(xcycwh: np.ndarray) -> np.ndarray:\n",
        "  # center_x center_y width height from https://roboflow.com/formats/yolov8-pytorch-txt.\n",
        "  xcycwh[:,0] = xcycwh[:,0] * IMAGE_WIDTH\n",
        "  xcycwh[:,1] = xcycwh[:,1] * IMAGE_HEIGHT\n",
        "  xcycwh[:,2] = xcycwh[:,2] * IMAGE_WIDTH\n",
        "  xcycwh[:,3] = xcycwh[:,3] * IMAGE_HEIGHT\n",
        "  return sv.xcycwh_to_xyxy(xcycwh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOBxWjUy4ztO"
      },
      "outputs": [],
      "source": [
        "folder_path = Path(dataset.location)/ \"train\"\n",
        "jpg_files = list(folder_path.glob('**/*.jpg'))\n",
        "txt_files = [file.with_suffix('.txt') for file in jpg_files]\n",
        "\n",
        "# To test repeatability on only 1 image\n",
        "# jpg_files = [\"/content/datasets/football-players-clustering-6/train/cd987c_0_7_png.rf.2410384de2ad3bc0088516227a167e60.jpg\"]\n",
        "# txt_files = [\"/content/datasets/football-players-clustering-6/train/cd987c_0_7_png.rf.2410384de2ad3bc0088516227a167e60.txt\"]\n",
        "\n",
        "detections_list = []\n",
        "for file in txt_files:\n",
        "  data = np.loadtxt(str(file))\n",
        "  class_id = data[:,0].astype(np.int32)\n",
        "  xyxy = convert_yolov8bbox_2_xyxy(data[:,1:])\n",
        "  detections_list.append(sv.Detections(xyxy=xyxy, class_id=class_id))\n",
        "  # break # only do 1 iteration to have only 1 image\n",
        "print(detections_list[0])\n",
        "print(len(detections_list))\n",
        "# print(jpg_files[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6v02MCFlM7d"
      },
      "source": [
        "### Visualise the detections on the image, double check if the conversion was successful\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5mMWwSLlLU4"
      },
      "outputs": [],
      "source": [
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "image= cv2.imread(str(jpg_files[0]))\n",
        "detections = detections_list[0]\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(annotated_image, detections=detections)\n",
        "sv.plot_image(image=annotated_image, size=(12, 12))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXt5BJ8bMoOI"
      },
      "outputs": [],
      "source": [
        "players_crops = [sv.crop_image(image, xyxy) for xyxy in detections.xyxy]\n",
        "sv.plot_images_grid(players_crops, grid_size=(5,5), titles = [f\"{i}\" for i in detections_list[0].class_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjlu0MIVP7qC"
      },
      "source": [
        "### Define helper methods and class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzM7Upv3hMBG"
      },
      "outputs": [],
      "source": [
        "class Experiment:\n",
        "  def __init__(self, model_path: str):\n",
        "    self.model_path = model_path\n",
        "    self.model = None\n",
        "    self.processor = None\n",
        "    self.results_list = []\n",
        "    self.clusters_list = []\n",
        "    self.execution_time_list = []\n",
        "    self.total_execution_time_list = []\n",
        "    if \"clip\" in model_path:\n",
        "      self.model_type = \"CLIP\"\n",
        "    elif \"siglip2\" in model_path:\n",
        "      self.model_type = \"SIGLIP2\"\n",
        "    elif \"siglip\" in model_path:\n",
        "      self.model_type = \"SIGLIP\"\n",
        "    elif \"resnet\" in model_path:\n",
        "      self.model_type = \"RESNET\"\n",
        "    else:\n",
        "      raise ValueError(\"Unknown model type\")\n",
        "\n",
        "\n",
        "  def init_model_n_processor(self):\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    if self.model_type == \"CLIP\":\n",
        "      self.model = CLIPVisionModel.from_pretrained(self.model_path).to(DEVICE)\n",
        "      self.processor = AutoProcessor.from_pretrained(self.model_path, use_fast=True)\n",
        "    elif self.model_type == \"SIGLIP2\":\n",
        "      self.model = AutoModel.from_pretrained(self.model_path, device_map=DEVICE).eval()\n",
        "      self.processor = AutoProcessor.from_pretrained(self.model_path, use_fast=True)\n",
        "      self.processor.image_processor.image_mean = [0.485, 0.456, 0.406]\n",
        "      self.processor.image_processor.image_std = [0.229, 0.224, 0.225]\n",
        "    elif self.model_type == \"SIGLIP\":\n",
        "      self.model = SiglipVisionModel.from_pretrained(self.model_path).to(DEVICE)\n",
        "      self.processor = AutoProcessor.from_pretrained(self.model_path, use_fast=True)\n",
        "      self.processor.image_processor.image_mean = [0.485, 0.456, 0.406]\n",
        "      self.processor.image_processor.image_std = [0.229, 0.224, 0.225]\n",
        "    elif self.model_type == \"RESNET\":\n",
        "      self.model = ResNetModel.from_pretrained(self.model_path).to(DEVICE)\n",
        "      self.processor = AutoFeatureExtractor.from_pretrained(self.model_path)\n",
        "\n",
        "\n",
        "  def forward(self, batch: np.ndarray) -> np.ndarray:\n",
        "    with torch.no_grad():\n",
        "      inputs = self.processor(images=batch, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "      if VISUALIZE_CROPS:\n",
        "        # Print processor information\n",
        "        # print(\"Processor info:\", self.processor)\n",
        "        if hasattr(self.processor, 'image_processor'):\n",
        "            print(\"Image Processor info:\", self.processor.image_processor)\n",
        "        else:\n",
        "            print(\"Image Processor: Not available or not an attribute of the processor\")\n",
        "        print(\"Size:\", inputs.pixel_values.shape)  # Final image size after processing\n",
        "\n",
        "        if hasattr(self.processor, 'size'):\n",
        "          print(\"Resizing:\", self.processor.size)  # Resizing settings\n",
        "        else:\n",
        "          print(\"Resizing: Not specified\")\n",
        "\n",
        "        if hasattr(self.processor, 'crop_size'):\n",
        "          print(\"Cropping:\", self.processor.crop_size)  # Cropping settings\n",
        "        else:\n",
        "          print(\"Cropping: Not specified\")\n",
        "\n",
        "        if hasattr(self.processor, 'image_mean') and hasattr(self.processor, 'image_std'):\n",
        "          print(\"Normalization:\", self.processor.image_mean, self.processor.image_std)  # Normalization settings\n",
        "        else:\n",
        "          print(\"Normalization: Not specified\")\n",
        "\n",
        "        for idx, image in enumerate(inputs.pixel_values):\n",
        "            if idx in [1,8,12]:\n",
        "              original_image = batch[idx]\n",
        "              image_np = image.cpu().numpy()\n",
        "              if image_np.shape[0] == 3:  # If shape is [3, H, W]\n",
        "                  image_np = image_np.transpose(1, 2, 0)\n",
        "              else:\n",
        "                  print(image_np.shape)\n",
        "                  # image_np = image_np.squeeze(0)  # Remove the channel dimension\n",
        "                  # Stack the single channel 3 times to create a 3-channel image for visualization\n",
        "                  image_np = np.stack([image_np, image_np, image_np], axis=-1)\n",
        "\n",
        "              # Display side-by-side\n",
        "              fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "              axs[0].imshow(original_image)\n",
        "              axs[0].set_title(\"Original Image\")\n",
        "              axs[1].imshow(image_np)\n",
        "              axs[1].set_title(\"Preprocessed Image\")\n",
        "              plt.show()\n",
        "\n",
        "      if self.model_type == \"SIGLIP2\":\n",
        "        embeddings = self.model.get_image_features(**inputs).cpu().numpy()\n",
        "      else:\n",
        "        outputs = self.model(**inputs)\n",
        "        if self.model_type == \"RESNET\":\n",
        "          embeddings = torch.mean(outputs.last_hidden_state, dim=[2, 3]).cpu().numpy()\n",
        "        else:\n",
        "          embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
        "      return embeddings\n",
        "\n",
        "\n",
        "  def clean_up(self):\n",
        "    self.model = None\n",
        "    self.processor = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8QB7zMMesiU"
      },
      "outputs": [],
      "source": [
        "def get_best_results_n_clusters(b_clusters: np.ndarray, b_class_id: np.ndarray)-> Tuple[np.ndarray, np.ndarray]:\n",
        "  '''\n",
        "    Compares predicted clusters (b_clusters) with ground truth class IDs (b_class_id)\n",
        "    and potentially inverts the clusters to achieve the best possible accuracy.\n",
        "\n",
        "    Setting all predictions to 1 or 0 will have at least a 50% success rate,\n",
        "    so the classifier cannot perform worse than that.\n",
        "    The assignment of cluster 0 and cluster 1 is arbitrary.\n",
        "    Inverting the results to the \"best result\" corresponds to actual classification results.\n",
        "\n",
        "    Args:\n",
        "        b_clusters (np.ndarray): Predicted cluster assignments (0 or 1).\n",
        "        b_class_id (np.ndarray): Ground truth class IDs (0 or 1).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]: A tuple containing:\n",
        "            - A boolean array indicating whether each prediction is correct after potential inversion.\n",
        "            - The cluster assignments (0 or 1) after potential inversion.\n",
        "  '''\n",
        "\n",
        "  result = b_clusters == b_class_id\n",
        "  if result.sum() < len(clusters)/2:\n",
        "    b_clusters = ~b_clusters\n",
        "    result = b_clusters == b_class_id\n",
        "  return result, b_clusters.astype(np.int32)\n",
        "\n",
        "def save_results_to_google_drive(experiments_list: list, batch_size: int, is_iteration=False):\n",
        "  if is_iteration:\n",
        "    filename = str(Path(FOLDER_DIR ) / (\"experiments_list_batch32_it\" + str(batch_size) + \".pkl\"))\n",
        "  else:\n",
        "    filename = str(Path(FOLDER_DIR ) / (\"experiments_list_batch\" + str(batch_size) + \".pkl\"))\n",
        "  with open(filename, 'wb') as f:\n",
        "    pickle.dump(experiments_list, f)\n",
        "\n",
        "def load_results_from_google_drive(batch_size: list, is_iteration=False):\n",
        "  if is_iteration:\n",
        "    filename = str(Path(FOLDER_DIR ) / (\"experiments_list_batch32_it\" + str(batch_size) + \".pkl\"))\n",
        "  else:\n",
        "    filename = str(Path(FOLDER_DIR ) / (\"experiments_list_batch\" + str(batch_size) + \".pkl\"))\n",
        "  loaded_experiment_list = None\n",
        "  with open(filename, 'rb') as f:\n",
        "    loaded_experiment_list = pickle.load(f)\n",
        "  return loaded_experiment_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed9aywuCrTk4"
      },
      "source": [
        "### Init methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c484DVh7kNtj"
      },
      "outputs": [],
      "source": [
        "TSNE_reducer = TSNE(n_components=3, perplexity=17, random_state=0)\n",
        "PCA_reducer = PCA(n_components=3)\n",
        "Umap_reducer = umap.UMAP(n_components=3)\n",
        "KMeans_model = KMeans(n_clusters=2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VZBUMhRfyZf"
      },
      "source": [
        "### Run the evaluation and save the results to your google drive for future evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "X-WcWtWYoM-q"
      },
      "outputs": [],
      "source": [
        "if RUN_EXPERIMENTS:\n",
        "  DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"'force_all_finite' was renamed to 'ensure_all_finite'\")\n",
        "\n",
        "  testing_rep_emb = []\n",
        "  testing_rep_reduced = []\n",
        "  testing_rep_kmeans = []\n",
        "\n",
        "  for iteration in range(NUM_ITERATIONS):\n",
        "    experiments_list = [Experiment(model_path) for model_path in VERSIONS_TO_TEST] # prevent appending into infinity, create objects anew\n",
        "    for batch_size in BATCH_SIZE_ARRAY:\n",
        "      for k, exp in enumerate(experiments_list):\n",
        "        print(f\"Iteration: {iteration} / {NUM_ITERATIONS -1 }\")\n",
        "        print(f\"Model: {exp.model_path}, {k} / {len(experiments_list)-1}\")\n",
        "        print(\"Batch size:\", batch_size)\n",
        "        exp.init_model_n_processor()\n",
        "        for i, image_path in tqdm(enumerate(jpg_files), desc='per image', total=len(jpg_files)):\n",
        "            image = cv2.imread(str(image_path))\n",
        "            players_crops = [sv.crop_image(image, xyxy) for xyxy in detections_list[i].xyxy]\n",
        "            pillow_crops = [sv.cv2_to_pillow(crop) for crop in players_crops]\n",
        "            batches = chunked(pillow_crops, batch_size)\n",
        "\n",
        "            data = []\n",
        "            start_time = time.perf_counter()\n",
        "            for batch in batches:\n",
        "              data.append(exp.forward(batch))\n",
        "            end_time = time.perf_counter()\n",
        "            exp.execution_time_list.append(end_time - start_time)\n",
        "\n",
        "            data = np.concatenate(data)\n",
        "            projections = Umap_reducer.fit_transform(data)\n",
        "            # projections = PCA_reducer.fit_transform(data)\n",
        "            projections = np.round(projections, decimals=2)\n",
        "            # projections = TSNE_reducer.fit_transform(data)\n",
        "            clusters = np.array(KMeans_model.fit_predict(projections))\n",
        "\n",
        "\n",
        "            # testing_rep_emb.append(data)\n",
        "            # testing_rep_reduced.append(projections)\n",
        "            # testing_rep_kmeans.append(clusters)\n",
        "\n",
        "            total_time = time.perf_counter()\n",
        "            exp.total_execution_time_list.append(total_time - start_time)\n",
        "\n",
        "            result, clusters = get_best_results_n_clusters(clusters.astype(bool), detections_list[i].class_id.astype(bool))\n",
        "            exp.results_list.append(result.sum() / len(clusters))\n",
        "            exp.clusters_list.append(clusters)\n",
        "\n",
        "        exp.clean_up()\n",
        "        experiments_list[k] = exp\n",
        "\n",
        "        print(\"Mean accuracy: \", np.mean(exp.results_list))\n",
        "        print(\"Mean execution time: \", np.mean(exp.execution_time_list))\n",
        "        print(\"Mean FPS: \", 1/np.mean(exp.execution_time_list))\n",
        "        print(\"Double check exp.results_list length: \", len(exp.results_list))\n",
        "        print(exp.results_list)\n",
        "        print(\"\\n\")\n",
        "\n",
        "      save_results_to_google_drive(experiments_list, iteration, is_iteration=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clusters"
      ],
      "metadata": {
        "id": "CDE_7Ox7blXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for iteration1 in range(5):\n",
        "#     # are_same = np.array_equal(testing_rep_emb[iteration1][0], testing_rep_emb[0][0])\n",
        "#     # are_same = np.array_equal(testing_rep_reduced[iteration1][0], testing_rep_reduced[0][0])\n",
        "#     are_same = np.array_equal(testing_rep_kmeans[iteration1], testing_rep_kmeans[0])\n",
        "#     # print(f\"Iteration {iteration1} vs Iteration {0}: {'Same' if are_same else 'Different'}\")\n",
        "#     print(testing_rep_reduced[iteration1][0])\n"
      ],
      "metadata": {
        "id": "vA-hf2TxWFhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Bb_Gtsi46d"
      },
      "source": [
        "#### Visualise one of the results for some or all of the images for the last experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2C_ACsoi31Y"
      },
      "outputs": [],
      "source": [
        "def display_for_id(id: int, exp: Experiment):\n",
        "  image = cv2.imread(str(jpg_files[id]))\n",
        "  players_crops = [sv.crop_image(image, xyxy) for xyxy in detections_list[id].xyxy]\n",
        "  print(\"Score: \", exp.results_list[id])\n",
        "  sv.plot_images_grid(players_crops, grid_size=(5,5),\n",
        "                      titles = [f\"gt:{i} pred:{j}\" for i,j in zip(detections_list[id].class_id,exp.clusters_list[id])])\n",
        "\n",
        "try:\n",
        "  # display_for_id(np.argmax(exp.results_list), exp)\n",
        "  display_for_id(np.argmin(exp.results_list), exp)\n",
        "  # for id in range(len(exp.results_list)):\n",
        "  #   display_for_id(id, exp)\n",
        "except NameError:\n",
        "  print(\"No experiment was run therfore the plot won't work\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szrPcq56mC-1"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c27zR8MzaD4i"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTrWdv7CmH5b"
      },
      "outputs": [],
      "source": [
        "all_experiments_for_all_iterations=[]\n",
        "NUM_ITERATIONS_ARRAY = range(NUM_ITERATIONS)\n",
        "for it in NUM_ITERATIONS_ARRAY:\n",
        "  all_experiments_for_all_iterations.append(load_results_from_google_drive(it, is_iteration=True))\n",
        "\n",
        "num_images = len(all_experiments_for_all_iterations[0][0].results_list)\n",
        "rows = NUM_ITERATIONS * num_images\n",
        "accuracy_array = np.zeros((rows, len(VERSIONS_TO_TEST)))\n",
        "accuracy_array_3D = np.zeros((len(VERSIONS_TO_TEST), NUM_ITERATIONS, num_images))\n",
        "exec_time_array = np.zeros((rows, len(VERSIONS_TO_TEST)))\n",
        "total_exec_time_array = np.zeros((rows, len(VERSIONS_TO_TEST)))\n",
        "model_name_list = []\n",
        "\n",
        "for i_exp in range(len(all_experiments_for_all_iterations[0])): # for experiment, every batch has the same amount of methods in it\n",
        "  for i_batch in range(len(all_experiments_for_all_iterations)): # for iteration\n",
        "    try:\n",
        "      current_exp = all_experiments_for_all_iterations[i_batch][i_exp]\n",
        "      accuracy_array[i_batch*num_images:(i_batch+1)*num_images,i_exp] = current_exp.results_list\n",
        "      accuracy_array_3D[i_exp,i_batch,:] = current_exp.results_list\n",
        "      exec_time_array[i_batch*num_images:(i_batch+1)*num_images,i_exp] = current_exp.execution_time_list\n",
        "      total_exec_time_array[i_batch*num_images:(i_batch+1)*num_images,i_exp] = current_exp.total_execution_time_list\n",
        "    except:\n",
        "      print(f\"i_batch, {i_batch}\")\n",
        "      print(f\"i_exp, {i_exp}\")\n",
        "      print(\"An exception occurred\")\n",
        "\n",
        "  model_name_list.append(current_exp.model_path)\n",
        "\n",
        "mean_total_exec_speed_array = 1/np.mean(total_exec_time_array, axis=0)\n",
        "\n",
        "\n",
        "# Prepare naming for the plots\n",
        "method_names = model_name_list\n",
        "method_names = [name.split('/')[-1] for name in method_names] # remove everything before the forward slash\n",
        "method_names = [name.replace('base', 'b').replace('large', 'l').replace('resnet', 'ResNet').replace('siglip', 'SigLip').replace('clip', 'CLIP').replace('patch', 'p').replace('-vit', '') for name in method_names] # rename the parts of the names\n",
        "colors = [ 'c' if 'SigLip2' in name else 'g' if 'SigLip' in name else 'r' if 'ResNet' in name else 'b' for name in method_names]\n",
        "markers = ['s' if 'SigLip2' in name else 'o' if 'SigLip' in name else '*' if 'ResNet' in name else 'x' for name in method_names]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaooilC9aIc6"
      },
      "source": [
        "## Boxplots with accuracy and total execution time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_6NsEgWzPn0"
      },
      "outputs": [],
      "source": [
        "# Create a figure and axes for the boxplots\n",
        "fig, axes = plt.subplots(2, 1, figsize=(18, 12), gridspec_kw={'height_ratios': [1, 2]})  # Adjust height ratios\n",
        "\n",
        "\n",
        "# --- Accuracy ---\n",
        "bp1 = axes[0].boxplot(accuracy_array, patch_artist=True, medianprops=dict(color=\"black\")) # patch_artist=True to be able to color the boxes\n",
        "axes[0].set_title('Accuracy')\n",
        "axes[0].set_xticklabels(method_names, rotation=45, ha='right')\n",
        "for box, color in zip(bp1['boxes'], colors):\n",
        "    box.set_facecolor(color)\n",
        "\n",
        "\n",
        "# --- Total Execution Time ---\n",
        "bp3 = axes[1].boxplot(1/total_exec_time_array, patch_artist=True, medianprops=dict(color=\"black\"))\n",
        "axes[1].set_title('Total Execution Speed [FPS]')\n",
        "axes[1].set_xticklabels(method_names, rotation=45, ha='right')\n",
        "for box, color in zip(bp3['boxes'], colors):\n",
        "    box.set_facecolor(color)\n",
        "# axes[0].grid(True)\n",
        "# axes[1].grid(True)\n",
        "\n",
        "\n",
        "# Calculate and plot average values for Accuracy\n",
        "means_acc = np.mean(accuracy_array, axis=0)\n",
        "axes[0].scatter(np.arange(1, len(method_names) + 1), means_acc, marker='x', color='pink', s=100, label='Mean', zorder=10)\n",
        "means_total_exec = np.mean(1/total_exec_time_array, axis=0)\n",
        "axes[1].scatter(np.arange(1, len(method_names) + 1), means_total_exec, marker='x', color='pink', s=100, label='Mean', zorder=10)\n",
        "\n",
        "\n",
        "for ax in axes:\n",
        "  ax.legend()\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoWtiq47YKTz"
      },
      "source": [
        "### Summary: Mean Results Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_uxIrvOEqsu"
      },
      "outputs": [],
      "source": [
        "# Calculate mean accuracy for each model\n",
        "mean_accuracy_array = np.mean(accuracy_array, axis=0)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "\n",
        "for i in range(len(method_names)):\n",
        "    markersize = 8 if markers[i] == 'o' else 10  # Smaller circles\n",
        "    linewidth = 2 if markers[i] == 'x' else 1  # Thicker crosses\n",
        "    ax.scatter(mean_total_exec_speed_array[i], mean_accuracy_array[i],\n",
        "               color=colors[i], marker=markers[i], label=method_names[i],\n",
        "               s=markersize**2, linewidth=linewidth)  # s=markersize**2 for area scaling\n",
        "\n",
        "# Use adjust_text to prevent label overlap\n",
        "texts = []\n",
        "siglip_crowded = []\n",
        "for i, txt in enumerate(method_names):\n",
        "    # if 'SigLip' in txt and 'SigLip-b' not in txt:\n",
        "    if 'SigLip' in txt:\n",
        "      siglip_crowded.append(ax.text(mean_total_exec_speed_array[i], mean_accuracy_array[i], txt))\n",
        "    else:\n",
        "      texts.append(ax.text(mean_total_exec_speed_array[i], mean_accuracy_array[i], txt))\n",
        "\n",
        "adjust_text(texts,\n",
        "            expand_points=(2, 2),  # Increase space around points\n",
        "            autoalign='y', # Align vertically\n",
        "            only_move={'points':'y', 'texts':'y'}, # Only move in y direction\n",
        "            )\n",
        "adjust_text(siglip_crowded,\n",
        "            expand_points=(2, 2),  # Increase space around points\n",
        "            arrowprops=dict(arrowstyle=\"-\", color='gray', lw=0.5), # Add gray arrows\n",
        "            autoalign='y', # Align vertically\n",
        "            only_move={'points':'y', 'texts':'y'}, # Only move in y direction\n",
        "            )\n",
        "\n",
        "# Set plot labels and title\n",
        "ax.set_xlabel('Mean Total Execution Speed [FPS]')\n",
        "ax.set_ylabel('Mean Accuracy')\n",
        "ax.set_title('Mean Accuracy vs. Mean Total Execution Speed [FPS] for a given model combined with UMAP and K-Means')\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMkCC_VLCZ6T"
      },
      "source": [
        "# Repeatability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2FLUaeUoC09"
      },
      "outputs": [],
      "source": [
        "all_experiments_for_all_iterations=[]\n",
        "NUM_ITERATIONS_ARRAY = range(NUM_ITERATIONS)\n",
        "for it in NUM_ITERATIONS_ARRAY:\n",
        "  all_experiments_for_all_iterations.append(load_results_from_google_drive(it, is_iteration=True))\n",
        "\n",
        "# Settings\n",
        "show_plot_for_each_exp = False\n",
        "show_percentage_differences = True\n",
        "show_percentage_differences_text = False\n",
        "\n",
        "accuracy_diff_list = []\n",
        "exec_time_diff_list = []\n",
        "total_exec_time_diff_list = []\n",
        "model_name_list = []\n",
        "\n",
        "for i_exp in range(len(all_experiments_for_all_iterations[0])): # for experiment, every batch has the same amount of methods in it\n",
        "  mean_results_list = []\n",
        "  mean_exec_time_list = []\n",
        "  mean_total_exec_time_list = []\n",
        "  for i_batch in range(len(all_experiments_for_all_iterations)): # for iteration\n",
        "    current_exp = all_experiments_for_all_iterations[i_batch][i_exp]\n",
        "    mean_results_list.append(np.mean(current_exp.results_list))\n",
        "    mean_exec_time_list.append(np.mean(current_exp.execution_time_list))\n",
        "    mean_total_exec_time_list.append(np.mean(current_exp.total_execution_time_list))\n",
        "\n",
        "  if show_plot_for_each_exp:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
        "    ax1.plot(NUM_ITERATIONS_ARRAY, mean_results_list, label=\"Mean Accuracy\")\n",
        "    ax1.set_xlabel('Batch Size')\n",
        "    ax1.set_ylabel('Mean Accuracy')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(NUM_ITERATIONS_ARRAY, mean_exec_time_list, label=\"Mean Exec time\")\n",
        "    ax2.plot(NUM_ITERATIONS_ARRAY, mean_total_exec_time_list, label=\"Mean Total Exec time\")\n",
        "    ax2.set_xlabel('Batch Size')\n",
        "    ax2.set_ylabel('Mean Execution Time')\n",
        "    ax2.legend()\n",
        "\n",
        "    fig.suptitle(\"Influence of Batch Size on Performance for \" + current_exp.model_path, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "  if show_percentage_differences:\n",
        "    mean_results_list = np.array(mean_results_list)\n",
        "    mean_exec_time_list = np.array(mean_exec_time_list)\n",
        "    mean_total_exec_time_list = np.array(mean_total_exec_time_list)\n",
        "\n",
        "    accuracy_diff = ((np.max(mean_results_list) - np.min(mean_results_list)) / np.max(mean_results_list)) * 100\n",
        "    exec_time_diff = ((np.max(mean_exec_time_list) - np.min(mean_exec_time_list)) / np.max(mean_exec_time_list)) * 100\n",
        "    total_exec_time_diff = ((np.max(mean_total_exec_time_list) - np.min(mean_total_exec_time_list)) / np.max(mean_total_exec_time_list)) * 100\n",
        "\n",
        "    accuracy_diff_list.append(accuracy_diff)\n",
        "    exec_time_diff_list.append(exec_time_diff)\n",
        "    total_exec_time_diff_list.append(total_exec_time_diff)\n",
        "    model_name_list.append(current_exp.model_path)\n",
        "    if show_percentage_differences_text:\n",
        "      print(current_exp.model_path)\n",
        "      print(\"Accuracy difference: \", accuracy_diff)\n",
        "      print(\"Execution time difference: \", exec_time_diff)\n",
        "      print(\"Total execution time difference: \", total_exec_time_diff)\n",
        "\n",
        "if show_percentage_differences:\n",
        "  fig, ax = plt.subplots(figsize=(15, 6))\n",
        "  ax.plot(model_name_list, accuracy_diff_list, label=\"Accuracy Difference (%)\", marker='o')\n",
        "  # ax.set_xlabel(\"Model Name\")\n",
        "  ax.set_ylabel(\"Relative Accuracy Difference (%)\")\n",
        "  ax.set_title(\"Maximal relative mean accuracy difference across different models and iterations\")\n",
        "  ax.legend()\n",
        "  plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "  plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "  ax.set_xticklabels(method_names, rotation=45, ha='right')\n",
        "\n",
        "  print(\"Mean accuracy diff: \", np.mean(accuracy_diff_list))\n",
        "  print(\"Mean time diff: \", np.mean(total_exec_time_diff_list))\n",
        "  print(\"Max accuracy diff: \", np.max(accuracy_diff_list))\n",
        "  print(\"Max time diff: \", np.max(total_exec_time_diff_list))\n",
        "  print(\"Min accuracy diff: \", np.min(accuracy_diff_list))\n",
        "  print(\"Min time diff: \", np.min(total_exec_time_diff_list))\n",
        "\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(15, 6))\n",
        "  ax.plot(model_name_list, exec_time_diff_list, label=\"Execution Time Difference (%)\", marker='s')\n",
        "  ax.plot(model_name_list, total_exec_time_diff_list, label=\"Total Execution Time Difference (%)\", marker='^')\n",
        "  ax.axhline(y=0, color='gray', linestyle='--', label=\"Zero Difference\") # Line at y=0\n",
        "  # ax.set_xlabel(\"Model Name\")\n",
        "  ax.set_ylabel(\"Relative Time Difference (%)\")\n",
        "  ax.set_title(\"Maximal relative time difference between the slowest and fastest mean execution time across different models and iterations\")\n",
        "  ax.legend()\n",
        "  plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "  plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "  ax.set_xticklabels(method_names, rotation=45, ha='right')\n",
        "\n",
        "\n",
        "  #boxplot of the mean_acc vs. method_names\n",
        "  mean_acc = np.mean(accuracy_array_3D, axis=2)\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  bp = ax.boxplot(mean_acc.T, patch_artist=True, medianprops=dict(color=\"black\"))\n",
        "  ax.set_ylabel(\"Mean Accuracy\")\n",
        "  ax.set_title('Mean accuracy over 32 evaluations of the dataset')\n",
        "  ax.set_xticklabels(method_names, rotation=45, ha='right')\n",
        "  for box, color in zip(bp['boxes'], colors):\n",
        "      box.set_facecolor(color)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93xmNzD6e3jl"
      },
      "outputs": [],
      "source": [
        "for i in range(len(method_names)):\n",
        "  fig, ax = plt.subplots(figsize=(12, 4))  # Adjust figure size as needed\n",
        "  ax.boxplot(accuracy_array_3D[i])\n",
        "  ax.set_title(method_names[i])\n",
        "  ax.set_xlabel('ID of the image')\n",
        "  ax.set_ylabel('Accuracy')\n",
        "  plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVdX4Ehri53G"
      },
      "source": [
        "# Ablation study on influence of batch size on the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PLk--k71SsAt"
      },
      "outputs": [],
      "source": [
        "# Partially repeated code...\n",
        "# could most likely pack this into seperate function, keeping it like this to make sure the results are reproducible,\n",
        "# don't want unexpected effect, that I didn't observe during my initial evaluation.\n",
        "if DO_ABLATION_STUDY:\n",
        "  DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"'force_all_finite' was renamed to 'ensure_all_finite'\")\n",
        "\n",
        "  for batch_size in BATCH_SIZE_ARRAY:\n",
        "    for k, exp in enumerate(experiments_list):\n",
        "      print(\"Model:\", exp.model_path)\n",
        "      print(\"Batch size:\", batch_size)\n",
        "      exp.init_model_n_processor()\n",
        "      for i, image_path in tqdm(enumerate(jpg_files), desc='per image', total=len(jpg_files)):\n",
        "          image = cv2.imread(str(image_path))\n",
        "          players_crops = [sv.crop_image(image, xyxy) for xyxy in detections_list[i].xyxy]\n",
        "          pillow_crops = [sv.cv2_to_pillow(crop) for crop in players_crops]\n",
        "          batches = chunked(pillow_crops, batch_size)\n",
        "\n",
        "          data = []\n",
        "          start_time = time.perf_counter()\n",
        "          for batch in batches:\n",
        "            data.append(exp.forward(batch))\n",
        "          end_time = time.perf_counter()\n",
        "          exp.execution_time_list.append(end_time - start_time)\n",
        "\n",
        "          data = np.concatenate(data)\n",
        "          projections = Umap_reducer.fit_transform(data)\n",
        "          clusters = np.array(KMeans_model.fit_predict(projections))\n",
        "\n",
        "          total_time = time.perf_counter()\n",
        "          exp.total_execution_time_list.append(total_time - start_time)\n",
        "\n",
        "          result, clusters = get_best_results_n_clusters(clusters.astype(bool), detections_list[i].class_id.astype(bool))\n",
        "          exp.results_list.append(result.sum() / len(clusters))\n",
        "          exp.clusters_list.append(clusters)\n",
        "      exp.clean_up()\n",
        "      experiments_list[k] = exp\n",
        "\n",
        "      print(\"Mean: \", np.mean(exp.results_list))\n",
        "      print(\"Mean execution time: \", np.mean(exp.execution_time_list))\n",
        "      print(\"FPS: \", 1/np.mean(exp.execution_time_list))\n",
        "      print(exp.results_list)\n",
        "      print(\"\\n\")\n",
        "\n",
        "    save_results_to_google_drive(experiments_list, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In5hqHP7iBtl"
      },
      "outputs": [],
      "source": [
        "if DO_ABLATION_STUDY:\n",
        "  all_experiments_for_all_batches=[]\n",
        "  for batch_size in BATCH_SIZE_ARRAY:\n",
        "    all_experiments_for_all_batches.append(load_results_from_google_drive(batch_size))\n",
        "\n",
        "  # Settings\n",
        "  show_plot_for_each_exp = True\n",
        "  show_percentage_differences = True\n",
        "  show_percentage_differences_text = True\n",
        "\n",
        "  accuracy_diff_list = []\n",
        "  exec_time_diff_list = []\n",
        "  total_exec_time_diff_list = []\n",
        "  model_name_list = []\n",
        "\n",
        "  for i_exp in range(len(all_experiments_for_all_batches[0])): # for experiment, every batch has so many methods in it\n",
        "    mean_results_list = []\n",
        "    mean_exec_time_list = []\n",
        "    mean_total_exec_time_list = []\n",
        "    for i_batch in range(len(all_experiments_for_all_batches)): # for batch size\n",
        "      current_exp = all_experiments_for_all_batches[i_batch][i_exp]\n",
        "      mean_results_list.append(np.mean(current_exp.results_list))\n",
        "      mean_exec_time_list.append(np.mean(current_exp.execution_time_list))\n",
        "      mean_total_exec_time_list.append(np.mean(current_exp.total_execution_time_list))\n",
        "\n",
        "    if show_plot_for_each_exp:\n",
        "      fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
        "      ax1.plot(np.array(BATCH_SIZE_ARRAY), np.array(mean_results_list), label=\"Mean Accuracy\")\n",
        "      ax1.set_xlabel('Batch Size')\n",
        "      ax1.set_ylabel('Mean Accuracy')\n",
        "      ax1.legend()\n",
        "\n",
        "      ax2.plot(np.array(BATCH_SIZE_ARRAY), np.array(mean_exec_time_list), label=\"Mean Exec time\")\n",
        "      ax2.plot(np.array(BATCH_SIZE_ARRAY), np.array(mean_total_exec_time_list), label=\"Mean Total Exec time\")\n",
        "      ax2.set_xlabel('Batch Size')\n",
        "      ax2.set_ylabel('Mean Execution Time')\n",
        "      ax2.legend()\n",
        "\n",
        "      fig.suptitle(\"Influence of Batch Size on Performance for \" + current_exp.model_path, fontsize=16)\n",
        "      plt.show()\n",
        "\n",
        "    if show_percentage_differences:\n",
        "      mean_results_list = np.array(mean_results_list)\n",
        "      mean_exec_time_list = np.array(mean_exec_time_list)\n",
        "      mean_total_exec_time_list = np.array(mean_total_exec_time_list)\n",
        "\n",
        "      accuracy_diff = ((np.max(mean_results_list) - np.min(mean_results_list)) / np.max(mean_results_list)) * 100\n",
        "      exec_time_diff = ((mean_exec_time_list[0] - mean_exec_time_list[-1]) / mean_exec_time_list[0]) * 100\n",
        "      total_exec_time_diff = ((mean_total_exec_time_list[0] - mean_total_exec_time_list[-1]) / mean_total_exec_time_list[0]) * 100\n",
        "\n",
        "      accuracy_diff_list.append(accuracy_diff)\n",
        "      exec_time_diff_list.append(exec_time_diff)\n",
        "      total_exec_time_diff_list.append(total_exec_time_diff)\n",
        "      model_name_list.append(current_exp.model_path)\n",
        "      if show_percentage_differences_text:\n",
        "        print(current_exp.model_path)\n",
        "        print(\"Accuracy difference: \", accuracy_diff)\n",
        "        print(\"Execution time difference: \", exec_time_diff)\n",
        "        print(\"Total execution time difference: \", total_exec_time_diff)\n",
        "\n",
        "  if show_percentage_differences:\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "    ax.plot(model_name_list, accuracy_diff_list, label=\"Accuracy Difference (%)\", marker='o')\n",
        "    ax.set_xlabel(\"Model Name\")\n",
        "    ax.set_ylabel(\"Relative Accuracy Difference (%)\")\n",
        "    ax.set_title(\"Maximal accuracy difference across different models and batch sizes\")\n",
        "    ax.legend()\n",
        "    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "    ax.plot(model_name_list, exec_time_diff_list, label=\"Execution Time Difference (%)\", marker='s')\n",
        "    ax.plot(model_name_list, total_exec_time_diff_list, label=\"Total Execution Time Difference (%)\", marker='^')\n",
        "    ax.axhline(y=0, color='gray', linestyle='--', label=\"Zero Difference\") # Line at y=0\n",
        "    ax.set_xlabel(\"Model Name\")\n",
        "    ax.set_ylabel(\"Relative Time Difference (%)\")\n",
        "    ax.set_title(\"Relative time difference between batch size of 1 and 32 across different models\")\n",
        "    ax.legend()\n",
        "    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlapping elements\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}